---
title: "Parameter calibration: likelihood methods"
format: 
  html: 
    embed-resources: true
editor: visual
---

## Problem set

You will be asked submit (via Canvas) your rendered (or knitted) html document

```{r}
library(tidyverse)
```

### Part 1

Load dataset

```{r}
d <- read_csv(file = "https://data.ecoforecast.org/neon4cast-targets/phenology/phenology-targets.csv.gz", show_col_types = FALSE)
```

Filter the dataset to only include the site_id BART (Bartlett Experimental Forest in the White Mountains of New Hampshire) and the dates between 2019-01-01 and 2019-07-01. Convert the date to Day of Year (hint: use `lubridate:: yday()` function). Remove rows with gcc_90 equal to NA or gcc_sd equal to 0.

```{r}
bart_2019 <- d  %>%
  filter(site_id == "BART",
         datetime > as_date("2019-01-01"),
         datetime < as_date("2019-07-01"),
         variable == "gcc_90") %>%
  mutate(doy = yday(datetime)) %>% 
  filter(!is.na(observation),
         observation > 0)
```

**Question 1:** How is gcc_90 related to day of year?

**Answer 1:**

```{r}
#plot gcc_90 by day of year
#gcc = green chromatograph, greeness, green band normalizaed by red band and brightness
bart_2019 |> 
  ggplot()+
  geom_line(aes(x = doy, y = observation))
```

As the day of year (doy) increases, the gcc_90 stays relatively flat until a certain day, and then it rapidly increases, then stays flay but with less stabililty for the rest of the year.
  
**Question 2:** Use a histogram to examine the distribution of the gcc_90

**Answer 2:**

```{r}
#Add Answer
bart_2019 |> 
  ggplot()+
  geom_histogram(aes(x = observation))
```
gcc_90 is not normally distributed, and might be better described using a different probability distribution.
  
First create a function called \`pred_logistic' that is your process model. The model is the the logistic curve which is the equation $$P_1 + P_2 {{exp(P_3 + P_4 x)}\over{1+exp(P_3 + P_4 x)}}$$

**Question 3:** Is this process model a dynamic model? Why or why not?

**Answer 3:**
This model is not a dynamic model, because it does not rely upon the previous states.
  
**Question 4:** Based on the equation above, write a function that predicts the gcc_90 as a function of the parameters ($P$) and x where x is the DOY. Name that function `pred_logistic`.

**Answer 4:**

```{r}
#Add Answer
pred_logistic <- function(x, par){
  par[1] + par[2] * exp(par[3] + par[4] * x)/(1 + exp(par[3] + par[4] * x))
}
```

**Question 5:** Write a function that calculates the negative log-likelihood of the data given a set of parameters governing the process and data models. Assume a normal distribution and be sure to estimate the sd in the data model.

**Answer 5:**

```{r}
#Add Answer
LL_fn <- function(x, y, par){
  -sum(dnorm(y, mean = pred_logistic(x, par), sd = par[5], log = TRUE))
}
```

**Question 6:** Use the `optim` function to find the most likely parameter values. Use the following as starting values `par = c(0.34,0.11,-15,0.11, 1)` where the first four are the theta parameters from your process model and the fifth is the sd of your data model.

**Answer 6:**

```{r}
#Add Answer
#x <- bart_2019$doy
#y <- bart_2019$observation
fit <- optim(par = c(0.34,0.11,-15,0.11, 1), fn = LL_fn, method = "BFGS", x = bart_2019$doy, y = bart_2019$observation)

```

```{r}
ggplot()+
  geom_point(data = bart_2019, aes(x = doy, y = observation))+
  geom_line(aes(x = bart_2019$doy, y = pred_logistic(x = bart_2019$doy, par = fit$par)))
```

**Question 7:** Use your optimal parameters in the `pred_logistic` function to predict the data. Save this as the object `predicted`

**Answer 7:**

```{r}
#Add Answer
predicted <- pred_logistic(x = bart_2019$doy, par = fit$par)
```

**Question 8:** Calculate the residuals and plot a histogram of the residuals

**Answer 8:**

```{r}
#Add Answer
residuals <- bart_2019$observation - predicted
hist(residuals)
```

**Question 9:** How does the distribution of the data (Question 2) compare to the distribution of the residuals?

**Answer 9:**
The distribution of the data is extremely skewed with some outliers to the right, but the distribution of the residuals could be described by a normal distribution.

**Question 10:** Predict year 2020 using the process model parameters from the 2019 fit.

```{r}
#Add Answer
bart_2020 <- d  %>%
  filter(site_id == "BART",
         datetime > as_date("2020-01-01"),
         datetime < as_date("2020-07-01"),
         variable == "gcc_90") %>%
  mutate(doy = yday(datetime)) %>% 
  filter(!is.na(observation),
         observation > 0)

predicted <- pred_logistic(x = bart_2020$doy, par = fit$par)

```

**Answer 10:**

**Question 11:** Plot the forecast from Question 10 over the data from 2020 (I give the code for getting the 2020 data)

**Answer 11:**

```{r}

ggplot()+
  geom_point(data = bart_2020, aes(x = doy, y = observation))+
  geom_line(aes(x = bart_2020$doy, y = pred_logistic(x = bart_2020$doy, par = fit$par)))

```

**Question 12:** Do you think your model from 2019 is reasonable for predicting 2020?

**Answer 12:**

The model for 2019 seems to work very well for 2020 as well.

### Part 2 {#sec-q10}

Using the following data

```{r}
df <- read_csv("https://raw.githubusercontent.com/frec-5174/eco4cast-in-R-book/main/data/soil_respiration_module_data.csv", show_col_types = FALSE)
```

It is a dataset that reports soil respiration, soil temperature, and soil moisture over a year at the University of Michigan Biological Station (from Nave, L.E., N. Bader, and J.L. Klug)

The columns correspond to the following

-   doy = Day of Year\
-   soil_resp: Soil respiration (micromoles CO2 per m2 per second)\
-   soil_temp: Soil Temp (deg C) soil_moisture: Soil Moisture (%)\

Use maximum likelihood to estimate the parameters in the model that predicts the relationship between soil temperature and soil respiration using the Q10 function below

$$\theta_1 * \theta_2 ^{{(T - 20)}\over{10}}$$

Show all the steps to determine the most likely parameter values, report the parameter values, and plot the data and predictions on the same plot

```{r}
#look at data
ggplot(df) +
  geom_point(aes(x = soil_temp, y = soil_resp))
#define my q10 function
#x = soil_temp
#y = soil_resp
pred_q10 <- function(x, par){
  par[1] * par[2]^((x-20)/10)
}

#log likelihood function
LL_fn <- function(x, y, par){
  -sum(dnorm(y, mean = pred_q10(x, par), sd = par[3], log = TRUE))
}
#find most likely fit with optim
#starting with all params as 1
fit <- optim(par = c(1, 1, 1), fn = LL_fn, method = "BFGS", x = df$soil_temp, y = df$soil_resp)
#output parameter values
fit

#fit  plotted with actual data
ggplot(df) +
  geom_point(aes(x = doy, y = soil_resp))+
  geom_line(aes(x = doy, y = pred_q10(x = df$soil_temp, par = fit$par)))
```

