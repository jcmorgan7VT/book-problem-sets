---
title: "Parameter calibration: Bayesian methods"
format: html
editor: visual
---

## Problem set

Your task is to modify the code below to estimate the posterior distribution of parameters in Q10 function that was in the likelihood analysis exercise. Use the same data as used in the Q10 likelihood exercise.

```{r}
#| warning: FALSE

library(tidyverse)
library(patchwork)

#Build fake dataset
set.seed(100)
num_data_points <- 200
sd_data <- 0.25
par_true <- c(3, 0.5)
x <- runif(num_data_points, 0, 10)
y_true <- par_true[1] * (x / (x + par_true[2]))
y <- rnorm(length(y_true), mean = y_true, sd = sd_data)
```

```{r}
plot(x, y, ylim = c(0, par_true[1] + 2))
```

```{r}
#Set MCMC Configuration
num_iter <- 2000
num_pars <- 2
jump <- c(0.05, 0.05)

#Initialize chain
pars <- array(NA, dim = c(num_pars, num_iter))
pars[1, 1] <- 2
pars[2, 1] <- 1
log_likelihood_prior_current <- -10000000000

for(i in 2:num_iter){
  
  #Loop through parameter value
  
  for(j in 1:num_pars){
      #Randomly select new parameter values
    proposed_pars <- pars[, i - 1]
    proposed_pars[j] <- rnorm(1, mean = pars[j, i - 1], sd = jump[j])
    
    ##########################
    # PRIORS
    #########################
    #(remember that you multiply probabilities which mean you can add log(probability))
    log_prior <- dunif(proposed_pars[1], min = 0, max = 10, log = TRUE) + 
      dunif(proposed_pars[2], min = 0, max = 100, log = TRUE)
    
    #Likelihood.  
    #You could use:
    # pred <- process_model(x, pars = proposed_pars)
    # log_likelihood <- sum(dnorm(new_data, mean = pred, sd = sd_data, log = TRUE)
    # but we are looping here because it transitions well to the next section of the course
    log_likelihood <- rep(NA, length(x))
    pred <- rep(NA, length(x))
    for(m in 1:length(x)){
      ##########################
      # PROCESS MODEL
      #########################
      pred[m] <- proposed_pars[1] * (x[m] / (x[m] + proposed_pars[2]))
      ##########################
      # DATA MODEL
      #########################
      log_likelihood[m] <- dnorm(y[m], mean = pred[m], sd = sd_data, log = TRUE)
    }
    #Remember that you multiply probabilities which mean you can add log(probability)
    #Hence the use of sum
    log_likelihood <- sum(log_likelihood)
    
    ############################
    ###  PRIOR x LIKELIHOOD
    ############################
    #Combine the prior and likelihood
    #remember that you multiply probabilities which means you can add log(probability)
    log_likelihood_prior_proposed <- log_prior + log_likelihood
    
    #We want the ratio of new / old but since it is in log space we first
    #take the difference of the logs: log(new/old) = log(new) - log(old) 
    # and then take out of log space exp(log(new) - log(old))
    z <- exp(log_likelihood_prior_proposed - log_likelihood_prior_current)
    
    #Now pick a random number between 0 and 1
    r <- runif(1, min = 0, max = 1)
    #If z > r then accept the new parameters
    #Note: this will always happen if the new parameters are more likely than
    #the old parameters z > 1 means than z is always > r no matter what value of
    #r is chosen.  However it will accept worse parameter sets (P_new is less
    #likely then P_old - i.e., z < 1) in proportion to how much worse it is
    #For example: if z = 0.9 and then any random number drawn by runif that is
    #less than 0.90 will result in accepting the worse values (i.e., the slightly
    #worse values will be accepted a lot of the time).  In contrast, if z = 0.01
    #(i.e., the new parameters are much much worse), then they can still be accepted
    #but much more rarely because random r values of < 0.1 occur more rarely
    if(log(z) > log(r)){
      pars[j, i] <- proposed_pars[j]
      log_likelihood_prior_current <- log_likelihood_prior_proposed
    }else{
      pars[j, i] <- pars[j, i - 1]
      log_likelihood_prior_current <- log_likelihood_prior_current #this calculation isn't necessary but is here to show you the logic
    }
  }
}

```

```{r}
#| warning: FALSE

d <- tibble(iter = 1:num_iter,
            par1 = pars[1, ],
            par2 = pars[2, ]) %>%
  pivot_longer(-iter, values_to = "value", names_to = "parameter")
```

```{r}
#| warning: FALSE

p1 <- ggplot(d, aes(x = iter, y = value)) +
  geom_line() +
  facet_wrap(~parameter, scales = "free") +
  theme_bw()

p2 <- ggplot(d, aes(x = value)) +
  geom_histogram() +
  facet_wrap(~parameter, scales = "free") +
  theme_bw()

p1 / p2
```

**Question 1**: Provide the distribution and parameters describing the distribution for your prior distributions. Justify why you chose the distribution and parameters. (do not spend time looking at the literature for values to use to build prior distribution - just give plausible priors and say why their plausible)

**Answer 1:**

**Question 2:** Provide plots of your prior distributions.

**Answer 2:**

```{r}


```

**Question 3:** Modify the code above to estimate the posterior distribution of your parameters. Put your modified code below.

**Answer 3:**

```{r}


```

**Question 4:** Plot the your MCMC chain for all parameters (iteration \# will be the x-axis)

**Answer 4:**

```{r}


```

**Question 5:** Approximately how many iterations did it take your chain to converge to a straight line with constant variation around the line (i.e., a fuzzy caterpillar). This is the burn-in. If your chain did not converge, modify the `jump` variable for each parameters and/or increase your iterations. You should not need more than 10000 iterations for convergence so running the chain for a long period of time will not fix issues that could be fixed by modifying the `jump` variable. Also, pay attention to the `sd_data` parameter. You should estimate it as a parameter or set it to a reasonable value. If it is too small your chain will fail because the probability of the some of parameters that are explored functionally zero.

**Answer 5:**

**Question 6:** Remove the iterations between 1 and your burn-in number and plot the histograms for your parameters.

```{r}


```

**Answer 6:**

**Question 7:** Provide the mean and 95% Credible Intervals for each parameter

```{r}


```

**Answer 7:**

**Question 8:** Random select 1000 values from the parameters in your posterior distribution. Show the randomly selected values for each parameter as a histogram.

**Answer 8:**

```{r}


```

**Question 9:** Use the samples from Question 8 to generate posterior predictions of soil respiration at the observed temperature values (i.e., the same temperature data used in your model fit). Provide a plot with temperature on the x-axis and respiration on the y-axis. The plot should have the mean and 95% predictive uncertainty bounds (i.e., include uncertainty in parameters and in the data model)

**Answer 9:**

```{r}

```
